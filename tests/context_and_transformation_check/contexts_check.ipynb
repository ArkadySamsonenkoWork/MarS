{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46fd001-7f27-45e1-b40f-780649c5bef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..')))\n",
    "\n",
    "import mars\n",
    "from mars import spin_model, spectra_manager, constants, population, concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68997c1e-f941-4bd7-a2eb-df6ea80295c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import mars.population.transform as transform\n",
    "from mars.population.contexts import Context, SummedContext\n",
    "from mars import spin_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c0da5e-4ce2-4f2e-bede-219293cca04f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtype = torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00001a64-d266-416e-930d-9bc0f5292ce1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Create Samples for Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3eeae6e-ff45-4137-b1e5-a5139850f026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_samples():\n",
    "    g_tensor_1 = spin_model.Interaction((2.02, 2.04, 2.06), dtype=dtype)\n",
    "    zfs_1 = spin_model.DEInteraction((200 * 1e6, 50 * 1e6), dtype=dtype)  # D=200 MHz, E=50 MHz\n",
    "    g_tensor_2 = spin_model.Interaction((2.02, 2.04, 2.06), dtype=dtype)\n",
    "    zfs_2 = spin_model.DEInteraction((200 * 1e6, 50 * 1e6), dtype=dtype)\n",
    "    \n",
    "    base_spin_system = spin_model.SpinSystem(\n",
    "        electrons=[1.0],\n",
    "        g_tensors=[g_tensor_1],\n",
    "        electron_electron=[(0, 0, zfs_1)],\n",
    "        dtype=dtype,\n",
    "    )\n",
    "    sample_1 = spin_model.MultiOrientedSample(\n",
    "        base_spin_system=base_spin_system,\n",
    "        gauss=0.001,\n",
    "        lorentz=0.001,\n",
    "        mesh=(4, 4),\n",
    "        dtype=dtype,\n",
    "    )\n",
    "\n",
    "\n",
    "    g_tensor = spin_model.Interaction((2.02, 2.14, 2.16), dtype=dtype)\n",
    "    zfs = spin_model.DEInteraction((200 * 1e6, 70 * 1e6), dtype=dtype)\n",
    "    base_spin_system = spin_model.SpinSystem(\n",
    "        electrons=[1.0],\n",
    "        g_tensors=[g_tensor_2],\n",
    "        electron_electron=[(0, 0, zfs_2)],\n",
    "        dtype=dtype\n",
    "    )\n",
    "    sample_2 = spin_model.MultiOrientedSample(\n",
    "        base_spin_system=base_spin_system,\n",
    "        gauss=0.001,\n",
    "        lorentz=0.001,\n",
    "        mesh=(4, 4),\n",
    "        dtype=dtype,\n",
    ")\n",
    "    return sample_1, sample_2\n",
    "\n",
    "def get_eigen_basis(sample, filed: float):\n",
    "    magnetic_field = torch.tensor(filed)\n",
    "    F, _, _, Gz = sample.get_hamiltonian_terms()\n",
    "    H = F + Gz * magnetic_field\n",
    "    H = H.unsqueeze(-3)\n",
    "    values, vectors = torch.linalg.eigh(H)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c079e-72c3-45f9-94fe-457b2dec7a12",
   "metadata": {},
   "source": [
    "# 2. Create contexts functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f805cf8-3718-4b1b-b13a-2dea2eba9975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_contexts_type_1(sample_1, sample_2, basis_1, basis_2):\n",
    "    context_1 = Context(\n",
    "        basis=basis_1,\n",
    "        sample=sample_1,\n",
    "        init_populations=[0.0, 0.0, 1.0],\n",
    "        out_probs=torch.tensor([123.3, 3123, 111.0], dtype=dtype),\n",
    "        free_probs=torch.tensor([[-0.0, 100.0, 0.0], \n",
    "                                 [100.0, -0.0, 667.0], \n",
    "                                 [0.0, 667.0, -0.0]], dtype=dtype) * 0.0,\n",
    "        dtype=dtype\n",
    "    )\n",
    "    context_2 = Context(\n",
    "        basis=basis_2,\n",
    "        sample=sample_2,\n",
    "        init_populations=[0.0, 1.0, 0.0],\n",
    "        out_probs=torch.tensor([434.0, 1233.0, 4343.0], dtype=dtype),\n",
    "        free_probs=torch.tensor([[-0.0, 321.0, 123.0], \n",
    "                                 [321.0, -0.0, 454.0], \n",
    "                                 [123.0, 454.0, -0.0]], dtype=dtype) * 0.0,\n",
    "        dtype=dtype\n",
    "    )\n",
    "    return context_1, context_2\n",
    "    \n",
    "def create_contexts_type_2(sample_1, sample_2, basis_1, basis_2):\n",
    "    context_1 = Context(\n",
    "        basis=basis_1,\n",
    "        sample=sample_1,\n",
    "        init_populations=[0.5, 0.35, 0.15],\n",
    "        out_probs=[0.0, 200.3, 100.2],\n",
    "        free_probs=torch.tensor([[-0.0, 100.0, 0.0], \n",
    "                                 [100.0, -0.0, 100.0], \n",
    "                                 [0.0, 100.0, -0.0]], dtype=dtype),\n",
    "        dtype=dtype\n",
    "    )\n",
    "    context_2 = Context(\n",
    "        basis=basis_2,\n",
    "        sample=sample_2,\n",
    "        init_populations=[0.3, 0.4, 0.3], \n",
    "        out_probs=[111.0, 1234.0, 1232.0],\n",
    "        free_probs=torch.tensor([[0.0, 100.0, 0.0], \n",
    "                                 [100.0, 0.0, 200.0], \n",
    "                                 [0.0, 200.0, -2.0]], dtype=dtype),\n",
    "        dtype=dtype\n",
    "    )\n",
    "    return context_1, context_2\n",
    "    \n",
    "def create_contexts_type_3(sample_1, sample_2, basis_1, basis_2):\n",
    "    context_1 = Context(\n",
    "        basis=basis_1,\n",
    "        sample=sample_1,\n",
    "        init_populations=[0.5, 0.25, 0.25],\n",
    "        out_probs=[1000.0, 200.3, 100.2],\n",
    "        dephasing = [1e4, 1e5, 1e6],\n",
    "        dtype=dtype\n",
    "    )\n",
    "    context_2 = Context(\n",
    "        basis=basis_2,\n",
    "        sample=sample_2,\n",
    "        init_populations=[0.3, 0.4, 0.3], \n",
    "        out_probs=[111.0, 1234.0, 1232.0],\n",
    "        dephasing = [2e5, 1e4, 1e3],\n",
    "        dtype=dtype\n",
    "    )\n",
    "    return context_1, context_2\n",
    "    \n",
    "def get_context_pairs(\n",
    "    creator_func, \n",
    "    sample_a, \n",
    "    sample_b, \n",
    "    use_same_sample: bool = False\n",
    ") -> list[tuple]:\n",
    "    \"\"\"Generate context pairs for different basis combinations.\"\"\"\n",
    "    s1 = sample_a if use_same_sample else sample_a\n",
    "    s2 = sample_a if use_same_sample else sample_b\n",
    "\n",
    "    return [\n",
    "        creator_func(s1, s2, \"xyz\", \"zeeman\"),\n",
    "        creator_func(s1, s2, \"zfs\", \"multiplet\")\n",
    "    ]\n",
    "\n",
    "\n",
    "context_creators = [\n",
    "        create_contexts_type_1,\n",
    "        create_contexts_type_2,\n",
    "        create_contexts_type_3,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dd7010-32af-4104-a094-dfe16de8dc6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Create check Context functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2acc431-2533-442f-8215-35ccab451696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import mars.population.transform as transform\n",
    "from mars.population.contexts import Context, SummedContext\n",
    "from mars import spin_model\n",
    "\n",
    "def check_multiplication_correctness(\n",
    "    context_1: Context,\n",
    "    context_2: Context,\n",
    "    full_system_vectors_1: torch.Tensor,\n",
    "    full_system_vectors_2: torch.Tensor,\n",
    "    atol: float = 1e-6,\n",
    "    rtol: float = 1e-5\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Validate Kronecker product (@) of contexts representing independent subsystems.\n",
    "    \n",
    "    Physical rules tested:\n",
    "    - Hilbert space: H_total = H₁ ⊗ H₂  →  dim_total = dim₁ × dim₂\n",
    "    - Initial state: ρ_total = ρ₁ ⊗ ρ₂  (Kronecker product)\n",
    "    - Dynamics: K_total = K₁ ⊗ I₂ + I₁ ⊗ K₂  (sum of local operators)\n",
    "    - Basis transformation preserves unitarity\n",
    "    \"\"\"\n",
    "    full_system_vectors_tot = transform.batched_kron(\n",
    "        full_system_vectors_1, full_system_vectors_2\n",
    "    )\n",
    "    mul_context = context_1 @ context_2\n",
    "\n",
    "    # 1. Dimensionality check\n",
    "    dim1 = context_1.spin_system_dim\n",
    "    dim2 = context_2.spin_system_dim\n",
    "    dim_tot = mul_context.spin_system_dim\n",
    "    assert dim_tot == dim1 * dim2, \\\n",
    "        f\"Dimension mismatch: {dim1} ⊗ {dim2} = {dim_tot} (expected {dim1 * dim2})\"\n",
    "    \"\"\"\n",
    "    # 2. Initial populations: Kronecker product\n",
    "    pop1 = context_1.get_transformed_init_populations(full_system_vectors_1, normalize=False)\n",
    "    pop2 = context_2.get_transformed_init_populations(full_system_vectors_2, normalize=False)\n",
    "    pop_tot = mul_context.get_transformed_init_populations(full_system_vectors_tot, normalize=False)\n",
    "    \n",
    "    if pop1 is not None and pop2 is not None:\n",
    "        expected_pop = transform.batched_kron(pop1.unsqueeze(-1), pop2.unsqueeze(-1)).squeeze(-1)\n",
    "        assert torch.allclose(pop_tot, expected_pop, atol=atol, rtol=rtol), \\\n",
    "            \"Initial populations don't combine via Kronecker product\"\n",
    "        assert torch.allclose(pop_tot.sum(-1), torch.ones_like(pop_tot.sum(-1)), atol=1e-5, rtol=rtol), \\\n",
    "            \"Total probability not conserved after Kronecker product\"\n",
    "    \n",
    "    dens1 = context_1.get_transformed_init_density(full_system_vectors_1)\n",
    "    dens2 = context_2.get_transformed_init_density(full_system_vectors_2)\n",
    "    dens_tot = mul_context.get_transformed_init_density(full_system_vectors_tot)\n",
    "    \n",
    "    if dens1 is not None and dens2 is not None:\n",
    "        # Expected: ρ_tot = ρ₁ ⊗ ρ₂\n",
    "        expected_dens = transform.batched_kron(dens1, dens2)\n",
    "        assert torch.allclose(dens_tot, expected_dens, atol=atol, rtol=rtol), \\\n",
    "            \"Density matrices don't combine via Kronecker product\"\n",
    "        assert torch.allclose(dens_tot, dens_tot.conj().transpose(-2, -1), atol=1e-5, rtol=rtol), \\\n",
    "            \"Composite density matrix not Hermitian\"\n",
    "    \n",
    "\n",
    "    # 3. Out probs\n",
    "    probs1 = context_1.get_transformed_out_probs(full_system_vectors_1)\n",
    "    probs2 = context_2.get_transformed_out_probs(full_system_vectors_2)\n",
    "    probs_tot = mul_context.get_transformed_out_probs(full_system_vectors_tot)\n",
    "    \n",
    "    if probs1 is not None and probs2 is not None:\n",
    "        I1 = torch.ones(dim1, device=probs1.device, dtype=probs1.dtype)\n",
    "        I2 = torch.ones(dim2, device=probs2.device, dtype=probs2.dtype)\n",
    "        \n",
    "        # Broadcast to common batch shape\n",
    "        batch_shape = torch.broadcast_shapes(probs1.shape[:-1], probs2.shape[:-1])\n",
    "        probs1_exp = probs1.expand(batch_shape + (dim1, ))\n",
    "        probs2_exp = probs2.expand(batch_shape + (dim2,))\n",
    "        I1_exp = I1.expand(batch_shape + (dim1,))\n",
    "        I2_exp = I2.expand(batch_shape + (dim2,))\n",
    "        \n",
    "        expected_probs = transform.batched_kron(probs1_exp, I2_exp) + \\\n",
    "                         transform.batched_kron(I1_exp, probs2_exp)\n",
    "        assert torch.allclose(probs_tot, expected_probs, atol=atol, rtol=rtol), \\\n",
    "            \"Out matrices don't combine as K₁⊗I + I⊗K₂\"\n",
    "        \n",
    "    # 4. Free probs\n",
    "\n",
    "    probs1 = context_1.get_transformed_free_probs(full_system_vectors_1)\n",
    "    probs2 = context_2.get_transformed_free_probs(full_system_vectors_2)\n",
    "    probs_tot = mul_context.get_transformed_free_probs(full_system_vectors_tot)\n",
    "\n",
    "    if probs1 is not None and probs2 is not None:\n",
    "        I1 = torch.eye(dim1, device=probs1.device, dtype=probs1.dtype)\n",
    "        I2 = torch.eye(dim2, device=probs2.device, dtype=probs2.dtype)\n",
    "        \n",
    "        # Broadcast to common batch shape\n",
    "        batch_shape = torch.broadcast_shapes(probs1.shape[:-2], probs2.shape[:-2])\n",
    "        probs1_exp = probs1.expand(batch_shape + (dim1, dim1))\n",
    "        probs2_exp = probs2.expand(batch_shape + (dim2, dim2))\n",
    "        I1_exp = I1.expand(batch_shape + (dim1, dim1))\n",
    "        I2_exp = I2.expand(batch_shape + (dim2, dim2))\n",
    "        \n",
    "        expected_probs = transform.batched_kron(probs1_exp, I2_exp) + \\\n",
    "                         transform.batched_kron(I1_exp, probs2_exp)\n",
    "        print((probs_tot - expected_probs)[-1, 0])\n",
    "\n",
    "        assert torch.allclose(probs_tot, expected_probs, atol=atol, rtol=rtol), \\\n",
    "            \"Rate matrices don't combine as K₁⊗I + I⊗K₂\"\n",
    "     \"\"\"\n",
    "    \n",
    "    # 5. Superoperators: Liouville-space Kronecker sum\n",
    "    superop1 = context_1.get_transformed_free_superop(full_system_vectors_1)\n",
    "    superop2 = context_2.get_transformed_free_superop(full_system_vectors_2)\n",
    "    superop_tot = mul_context.get_transformed_free_superop(full_system_vectors_tot)\n",
    "    \n",
    "    if superop1 is not None and superop2 is not None:\n",
    "        # Expected: R_tot = R₁ ⊗ I_Liouv + I_Liouv ⊗ R₂\n",
    "        # where I_Liouv has dimension (dim², dim²)\n",
    "        dim1_sq = dim1 * dim1\n",
    "        dim2_sq = dim2 * dim2\n",
    "        I1_liouv = torch.eye(dim1_sq, device=superop1.device, dtype=superop1.dtype)\n",
    "        I2_liouv = torch.eye(dim2_sq, device=superop2.device, dtype=superop2.dtype)\n",
    "        \n",
    "        batch_shape = torch.broadcast_shapes(superop1.shape[:-2], superop2.shape[:-2])\n",
    "        superop1_exp = superop1.expand(batch_shape + (dim1_sq, dim1_sq))\n",
    "        superop2_exp = superop2.expand(batch_shape + (dim2_sq, dim2_sq))\n",
    "        I1_exp = I1_liouv.expand(batch_shape + (dim1_sq, dim1_sq))\n",
    "        I2_exp = I2_liouv.expand(batch_shape + (dim2_sq, dim2_sq))\n",
    "        \n",
    "        expected_superop = transform.batched_kron(superop1_exp, I2_exp) + \\\n",
    "                           transform.batched_kron(I1_exp, superop2_exp)\n",
    "        \n",
    "        expected_superop = transform.reshape_superoperator_tensor_to_kronecker_basis(\n",
    "            expected_superop, subsystem_dims=[dim1, dim2]\n",
    "        )\n",
    "        assert torch.allclose(superop_tot, expected_superop, atol=atol, rtol=rtol), \\\n",
    "            \"Superoperators don't combine via Liouville Kronecker sum\"\n",
    "\n",
    "    if mul_context.basis is not None:\n",
    "        U = mul_context.basis\n",
    "        U_dag = U.conj().transpose(-2, -1)\n",
    "        identity = torch.eye(U.shape[-1], device=U.device, dtype=U.dtype)\n",
    "        prod = U_dag @ U\n",
    "        assert torch.allclose(prod, identity.expand_as(prod), atol=1e-5), \\\n",
    "            \"Composite basis transformation not unitary\"\n",
    "    \n",
    "    print(\"Multiplication test passed: dimensions, populations, densities, rates, superoperators\")\n",
    "\n",
    "\n",
    "def check_sum_correctness(\n",
    "    context_1: Context,\n",
    "    context_2: Context,\n",
    "    full_system_vectors: torch.Tensor,\n",
    "    atol: float = 1e-6,\n",
    "    rtol: float = 1e-5\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Validate addition (+) of contexts representing parallel relaxation mechanisms.\n",
    "    \n",
    "    Physical rules tested:\n",
    "    - Dimensions remain unchanged (same Hilbert space)\n",
    "    - Populations sum (if both defined)\n",
    "    - Rate matrices sum element-wise\n",
    "    - Superoperators sum element-wise\n",
    "    - Detailed balance preserved in summed thermal rates\n",
    "    \"\"\"\n",
    "    sum_context = context_1 + context_2\n",
    "    \n",
    "    # 1. Dimensionality preserved\n",
    "    dim1 = context_1.spin_system_dim\n",
    "    dim2 = context_2.spin_system_dim\n",
    "    dim_sum = sum_context.spin_system_dim\n",
    "    assert dim1 == dim2 == dim_sum, \\\n",
    "        f\"Dimension mismatch in sum: {dim1} + {dim2} = {dim_sum}\"\n",
    "    \n",
    "    pop1 = context_1.get_transformed_init_populations(full_system_vectors, normalize=False)\n",
    "    pop2 = context_2.get_transformed_init_populations(full_system_vectors, normalize=False)\n",
    "    pop_sum = sum_context.get_transformed_init_populations(full_system_vectors, normalize=False)\n",
    "    \n",
    "    if pop1 is not None and pop2 is not None:\n",
    "        expected_pop = pop1 + pop2\n",
    "        assert torch.allclose(pop_sum, expected_pop, atol=atol, rtol=rtol), \\\n",
    "            \"Populations don't sum correctly\"\n",
    "    \n",
    "    dens1 = context_1.get_transformed_init_density(full_system_vectors)\n",
    "    dens2 = context_2.get_transformed_init_density(full_system_vectors)\n",
    "    dens_sum = sum_context.get_transformed_init_density(full_system_vectors)\n",
    "    \n",
    "    if dens1 is not None and dens2 is not None:\n",
    "        expected_dens = dens1 + dens2\n",
    "        assert torch.allclose(dens_sum, expected_dens, atol=atol, rtol=rtol), \\\n",
    "            \"Density matrices don't sum correctly\"\n",
    "        \n",
    "        # Hermiticity preserved after summation\n",
    "        assert torch.allclose(dens_sum, dens_sum.conj().transpose(-2, -1), atol=1e-5), \\\n",
    "            \"Summed density matrix not Hermitian\"\n",
    "        \n",
    "        # Trace should be sum of individual traces\n",
    "        trace1 = torch.diagonal(dens1, dim1=-2, dim2=-1).sum(-1)\n",
    "        trace2 = torch.diagonal(dens2, dim1=-2, dim2=-1).sum(-1)\n",
    "        trace_sum = torch.diagonal(dens_sum, dim1=-2, dim2=-1).sum(-1)\n",
    "        assert torch.allclose(trace_sum, trace1 + trace2, atol=1e-5), \\\n",
    "            \"Trace not additive under summation\"\n",
    "    \n",
    "    # 4. Rate matrices sum\n",
    "    probs1 = context_1.get_transformed_free_probs(full_system_vectors)\n",
    "    probs2 = context_2.get_transformed_free_probs(full_system_vectors)\n",
    "    probs_sum = sum_context.get_transformed_free_probs(full_system_vectors)\n",
    "    \n",
    "    if probs1 is not None and probs2 is not None:\n",
    "        expected_probs = probs1 + probs2\n",
    "        assert torch.allclose(probs_sum, expected_probs, atol=atol, rtol=rtol), \\\n",
    "            \"Rate matrices don't sum correctly\"\n",
    "    \n",
    "    # 5. Superoperators sum\n",
    "    superop1 = context_1.get_transformed_free_superop(full_system_vectors)\n",
    "    superop2 = context_2.get_transformed_free_superop(full_system_vectors)\n",
    "    superop_sum = sum_context.get_transformed_free_superop(full_system_vectors)\n",
    "    \n",
    "    if superop1 is not None and superop2 is not None:\n",
    "        expected_superop = superop1 + superop2\n",
    "        assert torch.allclose(superop_sum, expected_superop, atol=atol, rtol=rtol), \\\n",
    "            \"Superoperators don't sum correctly\"\n",
    "    print(\"Sum test passed: dimensions, populations, densities, rates, superoperators\")\n",
    "\n",
    "\n",
    "def check_density_transformation_correctness(\n",
    "    context: Context,\n",
    "    full_system_vectors: torch.Tensor,\n",
    "    atol: float = 1e-6,\n",
    "    rtol: float = 1e-5\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Validate density matrix transformation between bases.\n",
    "    \n",
    "    Physical rules tested:\n",
    "    - Unitary transformation: ρ_new = U ρ_old U†\n",
    "    - Hermiticity preservation: ρ = ρ†\n",
    "    - Trace preservation: Tr(ρ) = 1 (for normalized states)\n",
    "    - Eigenvalue spectrum invariance under unitary transformation\n",
    "    \"\"\"\n",
    "    if context.init_density is None and context.init_populations is None:\n",
    "        print(\"Density transformation test skipped: no initial density/populations\")\n",
    "        return\n",
    "    \n",
    "    dens_transformed = context.get_transformed_init_density(full_system_vectors)\n",
    "    \n",
    "    if dens_transformed is None:\n",
    "        print(\"Density transformation test skipped: transformation returned None\")\n",
    "        return\n",
    "    \n",
    "    dim = context.spin_system_dim\n",
    "    \n",
    "    # 1. Hermiticity check\n",
    "    assert torch.allclose(\n",
    "        dens_transformed, \n",
    "        dens_transformed.conj().transpose(-2, -1), \n",
    "        atol=atol\n",
    "    ), \"Transformed density matrix not Hermitian\"\n",
    "    \n",
    "    # 2. Trace preservation\n",
    "    trace = torch.diagonal(dens_transformed, dim1=-2, dim2=-1).sum(-1)\n",
    "    assert torch.allclose(trace, torch.ones_like(trace), atol=1e-5), \\\n",
    "        f\"Trace not preserved: mean={trace.mean().item():.6f} ≠ 1.0\"\n",
    "    \n",
    "    # 3. Positive semi-definiteness (eigenvalues ≥ 0)\n",
    "    # Only check if matrix is small enough for eigendecomposition\n",
    "    if dim <= 16:  # Practical limit for batched eigendecomposition\n",
    "        eigvals = torch.linalg.eigvalsh(dens_transformed.real)  # Hermitian → real eigenvalues\n",
    "        assert torch.all(eigvals >= -1e-8), \\\n",
    "            f\"Negative eigenvalues found: min={eigvals.min().item():.2e}\"\n",
    "    \n",
    "    # 4. If basis is identity, transformation should be identity\n",
    "    if context.basis is not None and context.basis.shape[-1] == dim:\n",
    "        # Check if basis is approximately identity\n",
    "        identity = torch.eye(dim, device=context.basis.device, dtype=context.basis.dtype)\n",
    "        if torch.allclose(context.basis, identity, atol=1e-6):\n",
    "            # Transformation should leave density unchanged (up to numerical error)\n",
    "            dens_original = context.init_density\n",
    "            if dens_original is not None:\n",
    "                assert torch.allclose(dens_transformed, dens_original, atol=atol, rtol=rtol), \\\n",
    "                    \"Identity basis transformation modified density matrix\"\n",
    "    \n",
    "    \n",
    "    print(\"✓ Density transformation test passed: Hermiticity, trace, positivity, consistency\")\n",
    "\n",
    "\n",
    "def direct_sum_batched(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the direct sum (block diagonal) of two batched square matrices.\n",
    "    \n",
    "    Args:\n",
    "        A: Tensor of shape (batch_size, n, n)\n",
    "        B: Tensor of shape (batch_size, m, m)\n",
    "    \n",
    "    Returns:\n",
    "        Tensor of shape (batch_size, n + m, n + m) with A and B on the diagonal blocks.\n",
    "    \"\"\"\n",
    "    n, n2 = A.shape[-2:]\n",
    "    m, m2 = B.shape[-2:]\n",
    "    \n",
    "    # Validate shapes\n",
    "    assert n == n2, f\"A must be square, got shape {A.shape}\"\n",
    "    assert m == m2, f\"B must be square, got shape {B.shape}\"\n",
    "    \n",
    "    batch_size = A.shape[:-2]\n",
    "    total_dim = n + m\n",
    "    \n",
    "    # Initialize zero tensor for result\n",
    "    result = torch.zeros(*batch_size, total_dim, total_dim, \n",
    "                         dtype=A.dtype, device=A.device)\n",
    "    \n",
    "    # Fill top-left block with A\n",
    "    result[..., :n, :n] = A\n",
    "    \n",
    "    # Fill bottom-right block with B\n",
    "    result[..., n:, n:] = B\n",
    "    \n",
    "    return result\n",
    "    \n",
    "    \n",
    "def check_concatenation_correctness(\n",
    "    context_1: Context,\n",
    "    context_2: Context,\n",
    "    full_system_vectors_1: torch.Tensor,\n",
    "    full_system_vectors_2: torch.Tensor,\n",
    "    atol: float = 1e-6,\n",
    "    rtol: float = 1e-5\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Validate concatenation of contexts representing distinct spin systems in a powder sample.\n",
    "    \n",
    "    Physical interpretation: Different molecular species/orientations coexisting in same sample.\n",
    "    Mathematical operation: Direct sum (block-diagonal composition).\n",
    "    \"\"\"\n",
    "    \n",
    "    concat_context = mars.concat([context_1, context_2])\n",
    "    full_system_vectors = direct_sum_batched(A=full_system_vectors_1, B=full_system_vectors_2)\n",
    "    \n",
    "    # 1. Dimensionality (direct sum: N_total = N₁ + N₂)\n",
    "    dim1 = context_1.spin_system_dim\n",
    "    dim2 = context_2.spin_system_dim\n",
    "    dim_concat = concat_context.spin_system_dim\n",
    "    assert dim_concat == dim1 + dim2, \\\n",
    "        f\"Dimension mismatch: {dim1} ⊕ {dim2} = {dim_concat} (expected {dim1 + dim2})\"\n",
    "    \n",
    "    # 2. Populations form block-diagonal structure\n",
    "    pop1 = context_1.get_transformed_init_populations(full_system_vectors_1, normalize=False)\n",
    "    pop2 = context_2.get_transformed_init_populations(full_system_vectors_2, normalize=False)\n",
    "    \n",
    "    \n",
    "    pop_concat = concat_context.get_transformed_init_populations(full_system_vectors, normalize=False)\n",
    "    \n",
    "    if pop1 is not None and pop2 is not None and pop_concat is not None:\n",
    "        expected_pop = torch.cat([pop1, pop2], dim=-1)\n",
    "        assert torch.allclose(pop_concat, expected_pop, atol=atol, rtol=rtol), \\\n",
    "            \"Populations don't concatenate correctly\"\n",
    "    \n",
    "    # 3. Rate matrices form block-diagonal structure\n",
    "    probs1 = context_1.get_transformed_free_probs(full_system_vectors_1)\n",
    "    probs2 = context_2.get_transformed_free_probs(full_system_vectors_2)\n",
    "    probs_concat = concat_context.get_transformed_free_probs(full_system_vectors)\n",
    "    \n",
    "    if probs1 is not None and probs2 is not None and probs_concat is not None:\n",
    "        # Build expected block-diagonal matrix\n",
    "        expected_probs = torch.zeros(\n",
    "            probs1.shape[:-2] + (dim1 + dim2, dim1 + dim2),\n",
    "            device=probs1.device, dtype=probs1.dtype\n",
    "        )\n",
    "        expected_probs[..., :dim1, :dim1] = probs1\n",
    "        expected_probs[..., dim1:, dim1:] = probs2\n",
    "        \n",
    "        assert torch.allclose(probs_concat, expected_probs, atol=atol, rtol=rtol), \\\n",
    "            \"Rate matrices don't form block-diagonal structure\"\n",
    "        \n",
    "        # Each block should independently conserve probability\n",
    "        col_sums1 = probs1.sum(-2)\n",
    "        col_sums2 = probs2.sum(-2)\n",
    "    \n",
    "    # 4. Density matrices form block-diagonal structure\n",
    "    dens1 = context_1.get_transformed_init_density(full_system_vectors_1)\n",
    "    dens2 = context_2.get_transformed_init_density(full_system_vectors_2)\n",
    "    dens_concat = concat_context.get_transformed_init_density(full_system_vectors)\n",
    "    \n",
    "    if dens1 is not None and dens2 is not None and dens_concat is not None:\n",
    "        expected_dens = torch.zeros(\n",
    "            dens1.shape[:-2] + (dim1 + dim2, dim1 + dim2),\n",
    "            device=dens1.device, dtype=dens1.dtype\n",
    "        )\n",
    "        expected_dens[..., :dim1, :dim1] = dens1\n",
    "        expected_dens[..., dim1:, dim1:] = dens2\n",
    "        \n",
    "        assert torch.allclose(dens_concat, expected_dens, atol=atol, rtol=rtol), \\\n",
    "            \"Density matrices don't form block-diagonal structure\"\n",
    "        \n",
    "        # Each block should have trace 1 (normalized states)\n",
    "\n",
    "        trace1 = torch.diagonal(dens1, dim1=-2, dim2=-1).sum(-1)\n",
    "        trace2 = torch.diagonal(dens2, dim1=-2, dim2=-1).sum(-1)\n",
    "        \n",
    "        assert torch.allclose(trace1, torch.ones_like(trace1), atol=1e-5, rtol=rtol), \\\n",
    "            \"Block 1 density matrix trace ≠ 1\"\n",
    "        assert torch.allclose(trace2, torch.ones_like(trace2), atol=1e-5, rtol=rtol), \\\n",
    "            \"Block 2 density matrix trace ≠ 1\"\n",
    "    \n",
    "    print(\"✓ Concatenation test passed: block-diagonal structure for populations, rates, densities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548a48d-4869-48e8-87c2-578cba2ae794",
   "metadata": {},
   "source": [
    "# 4. Create different type-context to for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa8d95c0-c935-4646-ad13-efadfee09147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_comprehensive_context_operations(dtype=torch.float64):\n",
    "    sample_1, sample_2 = create_samples()\n",
    "    vectors_1 = get_eigen_basis(sample_1, 0.1)\n",
    "    vectors_2 = get_eigen_basis(sample_2, 0.1)\n",
    "    \n",
    "    for creator in context_creators:\n",
    "        for ctx1, ctx2 in get_context_pairs(creator, sample_1, sample_2, use_same_sample=False):\n",
    "            # Core operations\n",
    "            check_multiplication_correctness(ctx1, ctx2, vectors_1, vectors_2)\n",
    "            check_concatenation_correctness(ctx1, ctx2, vectors_1, vectors_2)\n",
    "            check_density_transformation_correctness(ctx1, vectors_1)\n",
    "    \n",
    "    for creator in context_creators:\n",
    "        for ctx1, ctx2 in get_context_pairs(creator, sample_1, sample_2, use_same_sample=True):\n",
    "            check_sum_correctness(ctx1, ctx2, vectors_1)\n",
    "    \n",
    "    # Additional edge case: Context with explicit density matrix\n",
    "    print(\"\\nTesting explicit density matrix initialization...\")\n",
    "    rho0 = torch.tensor([[0.5, 0.1+0.05j, 0.0],\n",
    "                         [0.1-0.05j, 0.3, 0.0],\n",
    "                         [0.0, 0.0, 0.2]], dtype=torch.complex128)\n",
    "    context_rho = Context(\n",
    "        basis=\"zfs\",\n",
    "        sample=sample_1,\n",
    "        init_density=rho0,\n",
    "        free_probs=torch.tensor([[0.0, 1e5, 0.0], \n",
    "                                 [1e5, 0.0, 1e5], \n",
    "                                 [0.0, 1e5, 0.0]], dtype=dtype),\n",
    "        dtype=dtype\n",
    "    )\n",
    "    check_density_transformation_correctness(context_rho, vectors_1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✅ All context operation tests passed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecc562a8-9912-448a-a255-291554f79a04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplication test passed: dimensions, populations, densities, rates, superoperators\n",
      "✓ Concatenation test passed: block-diagonal structure for populations, rates, densities\n",
      "✓ Density transformation test passed: Hermiticity, trace, positivity, consistency\n",
      "Multiplication test passed: dimensions, populations, densities, rates, superoperators\n",
      "✓ Concatenation test passed: block-diagonal structure for populations, rates, densities\n",
      "✓ Density transformation test passed: Hermiticity, trace, positivity, consistency\n",
      "Multiplication test passed: dimensions, populations, densities, rates, superoperators\n",
      "✓ Concatenation test passed: block-diagonal structure for populations, rates, densities\n",
      "✓ Density transformation test passed: Hermiticity, trace, positivity, consistency\n",
      "Multiplication test passed: dimensions, populations, densities, rates, superoperators\n",
      "✓ Concatenation test passed: block-diagonal structure for populations, rates, densities\n",
      "✓ Density transformation test passed: Hermiticity, trace, positivity, consistency\n",
      "Multiplication test passed: dimensions, populations, densities, rates, superoperators\n",
      "✓ Concatenation test passed: block-diagonal structure for populations, rates, densities\n",
      "✓ Density transformation test passed: Hermiticity, trace, positivity, consistency\n",
      "Multiplication test passed: dimensions, populations, densities, rates, superoperators\n",
      "✓ Concatenation test passed: block-diagonal structure for populations, rates, densities\n",
      "✓ Density transformation test passed: Hermiticity, trace, positivity, consistency\n",
      "Sum test passed: dimensions, populations, densities, rates, superoperators\n",
      "Sum test passed: dimensions, populations, densities, rates, superoperators\n",
      "Sum test passed: dimensions, populations, densities, rates, superoperators\n",
      "Sum test passed: dimensions, populations, densities, rates, superoperators\n",
      "Sum test passed: dimensions, populations, densities, rates, superoperators\n",
      "Sum test passed: dimensions, populations, densities, rates, superoperators\n",
      "\n",
      "Testing explicit density matrix initialization...\n",
      "✓ Density transformation test passed: Hermiticity, trace, positivity, consistency\n",
      "\n",
      "============================================================\n",
      "✅ All context operation tests passed successfully!\n"
     ]
    }
   ],
   "source": [
    "test_comprehensive_context_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353682c-4c65-4849-820c-c659d9899ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef19ff3-700b-4b36-bc3a-bf3e2252d90d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
